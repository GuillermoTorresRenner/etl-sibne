#!/usr/bin/env node

import { ETLPipeline } from "./etl-pipeline.js";
import { logger } from "./utils/logger.js";
import { config } from "./config/database.js";
import MigrationReportGenerator from "../generate-migration-report.js";
import { spawn } from "child_process";
import { promisify } from "util";
import path from "path";
import { fileURLToPath } from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

/**
 * Ejecuta un script de Node.js de forma asÃ­ncrona
 */
async function executeNodeScript(scriptPath, description) {
  return new Promise((resolve, reject) => {
    logger.info(`ðŸš€ ${description}...`);

    const projectRoot = path.join(__dirname, "..");
    const fullScriptPath = path.join(projectRoot, scriptPath);

    const child = spawn("node", [fullScriptPath], {
      cwd: projectRoot,
      stdio: "inherit",
    });

    child.on("close", (code) => {
      if (code === 0) {
        logger.info(`âœ… ${description} completado exitosamente`);
        resolve(code);
      } else {
        logger.error(`âŒ ${description} fallÃ³ con cÃ³digo: ${code}`);
        reject(new Error(`${description} fallÃ³`));
      }
    });

    child.on("error", (error) => {
      logger.error(`âŒ Error ejecutando ${description}:`, error);
      reject(error);
    });
  });
}

/**
 * Ejecuta la migraciÃ³n integral: ETL + Binarios + Metadatos + Reporte
 */
async function runIntegralMigration(options) {
  try {
    logger.info("ðŸš€ INICIANDO MIGRACIÃ“N INTEGRAL SIBNE");
    logger.info("=====================================");

    // PASO 1: Ejecutar ETL principal
    logger.info("ðŸ“Š PASO 1: MigraciÃ³n de datos estructurados");
    const pipeline = new ETLPipeline();
    const stats = await pipeline.run(options);

    // PASO 2: Extraer archivos binarios
    logger.info("ðŸ“ PASO 2: ExtracciÃ³n de archivos binarios");
    await executeNodeScript(
      "extract-binaries.js",
      "ExtracciÃ³n de archivos binarios"
    );

    // PASO 3: Migrar metadatos de archivos
    logger.info("ðŸ—ƒï¸ PASO 3: MigraciÃ³n de metadatos de archivos");
    await executeNodeScript(
      "migrate-archivo-adjunto.js",
      "MigraciÃ³n de metadatos"
    );

    // PASO 4: Generar reporte final
    logger.info("ðŸ“‹ PASO 4: GeneraciÃ³n de reporte integral");
    await generateMigrationReport();

    // Resultado final
    if (stats.errors.length === 0) {
      logger.info("ðŸŽ‰ MIGRACIÃ“N INTEGRAL COMPLETADA EXITOSAMENTE");
      logger.info(
        "âœ… Datos migrados, archivos extraÃ­dos, metadatos sincronizados y reporte generado"
      );
      return 0;
    } else if (stats.success.length > 0) {
      logger.warn("âš ï¸ MIGRACIÃ“N INTEGRAL COMPLETADA CON ERRORES PARCIALES");
      logger.info(
        "âœ… Archivos extraÃ­dos, metadatos sincronizados y reporte generado"
      );
      return 1;
    } else {
      logger.error("ðŸ’¥ MIGRACIÃ“N INTEGRAL FALLÃ“");
      return 2;
    }
  } catch (error) {
    logger.error("ðŸ’¥ ERROR CRÃTICO EN MIGRACIÃ“N INTEGRAL:", error);
    throw error;
  }
}

/**
 * Genera el reporte de migraciÃ³n automÃ¡ticamente
 */
async function generateMigrationReport() {
  try {
    const generator = new MigrationReportGenerator();
    const reportPath = await generator.generateReport();
    logger.info(`âœ… Reporte generado exitosamente: ${reportPath}`);
  } catch (error) {
    logger.error("âŒ Error generando reporte de migraciÃ³n:", error);
    // No fallar la migraciÃ³n por error en reporte
  }
}

/**
 * ETL SIBNE - MigraciÃ³n de SQL Server a PostgreSQL
 *
 * Casos de uso:
 * - node src/index.js                              # MigraciÃ³n completa en modo directo
 * - node src/index.js --mode=csv                   # MigraciÃ³n completa vÃ­a CSV
 * - node src/index.js --tables=tabla1,tabla2      # Migrar tablas especÃ­ficas
 * - node src/index.js --sequential                 # Procesar tablas secuencialmente
 * - node src/index.js --help                       # Mostrar ayuda
 */

async function main() {
  const args = process.argv.slice(2);

  // Procesar argumentos
  const options = {
    mode: "csv", // SIEMPRE CSV para generar respaldos
    parallel: true,
    tablesFilter: null,
    excludePatterns: [], // Los filtros por defecto estÃ¡n en el pipeline
    integral: false, // Nueva opciÃ³n para migraciÃ³n integral
  };

  // Parsear argumentos
  for (const arg of args) {
    if (arg === "--help" || arg === "-h") {
      showHelp();
      process.exit(0);
    } else if (arg.startsWith("--mode=")) {
      options.mode = arg.split("=")[1];
    } else if (arg.startsWith("--tables=")) {
      options.tablesFilter = arg
        .split("=")[1]
        .split(",")
        .map((t) => t.trim());
    } else if (arg === "--sequential") {
      options.parallel = false;
    } else if (arg === "--integral") {
      options.integral = true;
    } else if (arg.startsWith("--exclude=")) {
      const excludeList = arg
        .split("=")[1]
        .split(",")
        .map((t) => t.trim());
      options.excludePatterns.push(...excludeList);
    }
  }

  // Validar modo
  if (!["direct", "csv"].includes(options.mode)) {
    logger.error("âŒ Modo invÃ¡lido. Use: direct o csv");
    process.exit(1);
  }

  // Decidir tipo de migraciÃ³n
  if (options.integral) {
    // MIGRACIÃ“N INTEGRAL: ETL + Binarios + Metadatos + Reporte
    try {
      const exitCode = await runIntegralMigration(options);
      process.exit(exitCode);
    } catch (error) {
      logger.error("ðŸ’¥ ERROR CRÃTICO EN MIGRACIÃ“N INTEGRAL:", error);
      process.exit(3);
    }
  } else {
    // MIGRACIÃ“N TRADICIONAL: Solo ETL
    logger.info("ðŸš€ INICIANDO ETL SIBNE - SOLO TABLAS DEL NEGOCIO");
    logger.info("=================================================");
    logger.info(`ðŸ“‹ Modo: CSV (siempre genera respaldos)`);
    logger.info(`âš¡ ParalelizaciÃ³n: ${options.parallel ? "SÃ­" : "No"}`);
    logger.info(
      `ðŸŽ¯ Tablas especÃ­ficas: ${
        options.tablesFilter
          ? options.tablesFilter.join(", ")
          : "Solo tablas del negocio"
      }`
    );
    logger.info(`ðŸš« Auto-excluye: AspNet*, __, sys, trace, MSreplication`);
    logger.info(`ðŸ”„ Concurrencia: ${config.etl.concurrency}`);
    logger.info(`ðŸ“¦ TamaÃ±o de lote: ${config.etl.batchSize}`);
    logger.info(`ðŸ’¾ CSV generados en: ${config.paths.csvOutput}`);

    const pipeline = new ETLPipeline();

    try {
      const stats = await pipeline.run(options);

      // CÃ³digo de salida basado en resultados
      if (stats.errors.length === 0) {
        logger.info("ðŸŽ‰ MIGRACIÃ“N COMPLETADA EXITOSAMENTE");

        // ðŸ“‹ Generar reporte automÃ¡ticamente al finalizar
        logger.info("ðŸ“‹ Generando reporte de migraciÃ³n...");
        await generateMigrationReport();

        process.exit(0);
      } else if (stats.success.length > 0) {
        logger.warn("âš ï¸ MIGRACIÃ“N COMPLETADA CON ERRORES PARCIALES");

        // ðŸ“‹ Generar reporte incluso con errores parciales
        logger.info("ðŸ“‹ Generando reporte de migraciÃ³n...");
        await generateMigrationReport();

        process.exit(1);
      } else {
        logger.error("ðŸ’¥ MIGRACIÃ“N FALLÃ“ COMPLETAMENTE");
        process.exit(2);
      }
    } catch (error) {
      logger.error("ðŸ’¥ ERROR CRÃTICO EN MIGRACIÃ“N:", error);
      process.exit(3);
    }
  }
}

/**
 * Mostrar ayuda
 */
function showHelp() {
  console.log(`
ðŸŽ¯ ETL SIBNE - MigraciÃ³n de SQL Server a PostgreSQL

USO:
  node src/index.js [opciones]

OPCIONES:
  --mode=MODE          Modo de migraciÃ³n: 'direct' o 'csv' (default: csv)
  --tables=TABLE1,TABLE2  Migrar solo tablas especÃ­ficas
  --sequential         Procesar tablas secuencialmente (no en paralelo)
  --integral           ðŸš€ MIGRACIÃ“N COMPLETA: ETL + Binarios + Metadatos + Reporte
  --exclude=PATTERN1,PATTERN2  Patrones adicionales a excluir
  --help, -h          Mostrar esta ayuda

MODOS:
  csv       MigraciÃ³n vÃ­a CSV intermedio (genera archivos de respaldo)
  direct    MigraciÃ³n directa SQL Server â†’ PostgreSQL (mÃ¡s rÃ¡pido)

EJEMPLOS:
  # ðŸš€ MIGRACIÃ“N INTEGRAL COMPLETA (RECOMENDADO)
  node src/index.js --integral

  # MigraciÃ³n tradicional (solo ETL)
  node src/index.js

  # Migrar solo tablas especÃ­ficas
  node src/index.js --tables=usuarios,productos,ventas

  # MigraciÃ³n secuencial (una tabla a la vez)
  node src/index.js --sequential

  # Excluir patrones adicionales
  node src/index.js --exclude=temp,backup

CONFIGURACIÃ“N:
  Las configuraciones se establecen en el archivo .env:
  - SA_PASSWORD: Password de SQL Server
  - PG_PASSWORD: Password de PostgreSQL
  - BATCH_SIZE: TamaÃ±o de lote para inserciÃ³n (default: 1000)
  - CONCURRENCY: Tablas a procesar en paralelo (default: 3)

LOGS:
  Los logs se guardan en la carpeta ./logs/
  - etl-combined.log: Todos los logs
  - etl-errors.log: Solo errores
  `);
}

// Manejo de seÃ±ales
process.on("SIGINT", () => {
  logger.info("ðŸ›‘ Recibida seÃ±al de interrupciÃ³n, cerrando ETL...");
  process.exit(130);
});

process.on("SIGTERM", () => {
  logger.info("ðŸ›‘ Recibida seÃ±al de terminaciÃ³n, cerrando ETL...");
  process.exit(143);
});

process.on("unhandledRejection", (reason, promise) => {
  logger.error("ðŸ’¥ Promise rechazada sin manejar:", { reason, promise });
  process.exit(1);
});

process.on("uncaughtException", (error) => {
  logger.error("ðŸ’¥ ExcepciÃ³n no capturada:", error);
  process.exit(1);
});

// Ejecutar programa principal
if (import.meta.url === `file://${process.argv[1]}`) {
  main().catch((error) => {
    logger.error("ðŸ’¥ Error fatal:", error);
    process.exit(1);
  });
}
